{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24223,"status":"ok","timestamp":1695088021420,"user":{"displayName":"Ali Ghadiri","userId":"10282190092396035743"},"user_tz":-600},"id":"ancVB5Vxtu9j","outputId":"801a8c08-b987-4098-d1cd-181cfc23e107"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24,"status":"ok","timestamp":1695088021421,"user":{"displayName":"Ali Ghadiri","userId":"10282190092396035743"},"user_tz":-600},"id":"LrJmFF27orM6","outputId":"bfaba094-1c6a-44dc-ccf1-4b7d5ce3b267"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/FairPrune\n"]}],"source":["%cd \"/content/drive/MyDrive/FairPrune\""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":639,"status":"ok","timestamp":1695030737669,"user":{"displayName":"Ali Ghadiri","userId":"16250926096536030149"},"user_tz":-600},"id":"crxHbzGFydAU","outputId":"9b90b8f4-f7ad-4e8e-d00d-1fca36240387"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/.shortcut-targets-by-id/1mE95vsJWdCLeyosiSlxTV5_-JveJMu0s/FairPrune\n"]}],"source":["%cd \"/content/drive/MyDrive/UNSW/FairPrune\"\n"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"bMMic7H0pAY3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1695084473181,"user_tz":-600,"elapsed":10334651,"user":{"displayName":"Ali Ghadiri","userId":"10282190092396035743"}},"outputId":"2ccad743-ac31-403b-c92c-24958cd4ca42"},"outputs":[{"output_type":"stream","name":"stdout","text":["CUDA is available: True \n","\n","Starting... \n","\n","{'train': 12809, 'val': 3203}\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","Fitz17kResNet18(\n","  (feature_extractor): ResNet(\n","    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu): ReLU(inplace=True)\n","    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","    (layer1): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (layer2): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (layer3): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (layer4): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","    (fc): Linear(in_features=512, out_features=3, bias=True)\n","  )\n",")\n","Epoch 0/19\n","--------------------\n","Current phase: train\n","train Loss: 0.7118 Acc: 0.6891 Balanced Accuracy: 0.6932 \n","Current phase: val\n","val Loss: 0.6898 Acc: 0.7143 Balanced Accuracy: 0.6506 \n","New leading accuracy: 0.7143303155899048\n","Checkpoint saved: /content/drive/MyDrive/FairPrune/Outputs/Resnet18_checkpoint_BASE.pth\n","Epoch 1/19\n","--------------------\n","Current phase: train\n","train Loss: 0.4627 Acc: 0.8156 Balanced Accuracy: 0.8194 \n","Current phase: val\n","val Loss: 0.6904 Acc: 0.7321 Balanced Accuracy: 0.6995 \n","New leading accuracy: 0.7321261167526245\n","Checkpoint saved: /content/drive/MyDrive/FairPrune/Outputs/Resnet18_checkpoint_BASE.pth\n","Epoch 2/19\n","--------------------\n","Current phase: train\n","train Loss: 0.3124 Acc: 0.8821 Balanced Accuracy: 0.8864 \n","Current phase: val\n","val Loss: 0.5976 Acc: 0.7796 Balanced Accuracy: 0.6982 \n","New leading accuracy: 0.779581606388092\n","Checkpoint saved: /content/drive/MyDrive/FairPrune/Outputs/Resnet18_checkpoint_BASE.pth\n","Epoch 3/19\n","--------------------\n","Current phase: train\n","train Loss: 0.2293 Acc: 0.9143 Balanced Accuracy: 0.9187 \n","Current phase: val\n","val Loss: 0.6342 Acc: 0.7880 Balanced Accuracy: 0.6910 \n","New leading accuracy: 0.7880111932754517\n","Checkpoint saved: /content/drive/MyDrive/FairPrune/Outputs/Resnet18_checkpoint_BASE.pth\n","Epoch 4/19\n","--------------------\n","Current phase: train\n","train Loss: 0.1734 Acc: 0.9382 Balanced Accuracy: 0.9425 \n","Current phase: val\n","val Loss: 0.6303 Acc: 0.7883 Balanced Accuracy: 0.7170 \n","New leading accuracy: 0.7883234024047852\n","Checkpoint saved: /content/drive/MyDrive/FairPrune/Outputs/Resnet18_checkpoint_BASE.pth\n","Epoch 5/19\n","--------------------\n","Current phase: train\n","train Loss: 0.1275 Acc: 0.9567 Balanced Accuracy: 0.9592 \n","Current phase: val\n","val Loss: 0.6186 Acc: 0.8224 Balanced Accuracy: 0.6984 \n","New leading accuracy: 0.8223540186882019\n","Checkpoint saved: /content/drive/MyDrive/FairPrune/Outputs/Resnet18_checkpoint_BASE.pth\n","Epoch 6/19\n","--------------------\n","Current phase: train\n","train Loss: 0.1018 Acc: 0.9651 Balanced Accuracy: 0.9678 \n","Current phase: val\n","val Loss: 0.6748 Acc: 0.8227 Balanced Accuracy: 0.6970 \n","New leading accuracy: 0.8226662278175354\n","Checkpoint saved: /content/drive/MyDrive/FairPrune/Outputs/Resnet18_checkpoint_BASE.pth\n","Epoch 7/19\n","--------------------\n","Current phase: train\n","train Loss: 0.0899 Acc: 0.9694 Balanced Accuracy: 0.9719 \n","Current phase: val\n","val Loss: 0.6761 Acc: 0.8071 Balanced Accuracy: 0.7185 \n","Epoch 8/19\n","--------------------\n","Current phase: train\n","train Loss: 0.0652 Acc: 0.9799 Balanced Accuracy: 0.9813 \n","Current phase: val\n","val Loss: 0.6749 Acc: 0.8089 Balanced Accuracy: 0.7247 \n","Epoch 9/19\n","--------------------\n","Current phase: train\n","train Loss: 0.0662 Acc: 0.9768 Balanced Accuracy: 0.9788 \n","Current phase: val\n","val Loss: 0.6932 Acc: 0.8180 Balanced Accuracy: 0.7274 \n","Epoch 10/19\n","--------------------\n","Current phase: train\n","train Loss: 0.0633 Acc: 0.9793 Balanced Accuracy: 0.9815 \n","Current phase: val\n","val Loss: 0.7004 Acc: 0.8195 Balanced Accuracy: 0.7178 \n","Epoch 11/19\n","--------------------\n","Current phase: train\n","train Loss: 0.0565 Acc: 0.9822 Balanced Accuracy: 0.9837 \n","Current phase: val\n","val Loss: 0.6563 Acc: 0.8305 Balanced Accuracy: 0.7110 \n","New leading accuracy: 0.830471396446228\n","Checkpoint saved: /content/drive/MyDrive/FairPrune/Outputs/Resnet18_checkpoint_BASE.pth\n","Epoch 12/19\n","--------------------\n","Current phase: train\n","train Loss: 0.0547 Acc: 0.9831 Balanced Accuracy: 0.9847 \n","Current phase: val\n","val Loss: 0.6661 Acc: 0.8267 Balanced Accuracy: 0.7128 \n","Epoch 13/19\n","--------------------\n","Current phase: train\n","train Loss: 0.0489 Acc: 0.9837 Balanced Accuracy: 0.9852 \n","Current phase: val\n","val Loss: 0.6718 Acc: 0.8286 Balanced Accuracy: 0.7153 \n","Epoch 14/19\n","--------------------\n","Current phase: train\n","train Loss: 0.0329 Acc: 0.9901 Balanced Accuracy: 0.9910 \n","Current phase: val\n","val Loss: 0.6581 Acc: 0.8417 Balanced Accuracy: 0.7314 \n","New leading accuracy: 0.8417108654975891\n","Checkpoint saved: /content/drive/MyDrive/FairPrune/Outputs/Resnet18_checkpoint_BASE.pth\n","Epoch 15/19\n","--------------------\n","Current phase: train\n","train Loss: 0.0269 Acc: 0.9923 Balanced Accuracy: 0.9931 \n","Current phase: val\n","val Loss: 0.6546 Acc: 0.8445 Balanced Accuracy: 0.7341 \n","New leading accuracy: 0.8445207476615906\n","Checkpoint saved: /content/drive/MyDrive/FairPrune/Outputs/Resnet18_checkpoint_BASE.pth\n","Epoch 16/19\n","--------------------\n","Current phase: train\n","train Loss: 0.0305 Acc: 0.9909 Balanced Accuracy: 0.9919 \n","Current phase: val\n","val Loss: 0.7028 Acc: 0.8373 Balanced Accuracy: 0.7086 \n","Epoch 17/19\n","--------------------\n","Current phase: train\n","train Loss: 0.0214 Acc: 0.9934 Balanced Accuracy: 0.9941 \n","Current phase: val\n","val Loss: 0.6609 Acc: 0.8483 Balanced Accuracy: 0.7206 \n","New leading accuracy: 0.8482671976089478\n","Checkpoint saved: /content/drive/MyDrive/FairPrune/Outputs/Resnet18_checkpoint_BASE.pth\n","Epoch 18/19\n","--------------------\n","Current phase: train\n","train Loss: 0.0278 Acc: 0.9909 Balanced Accuracy: 0.9916 \n","Current phase: val\n","val Loss: 0.6696 Acc: 0.8380 Balanced Accuracy: 0.7415 \n","Epoch 19/19\n","--------------------\n","Current phase: train\n","train Loss: 0.0228 Acc: 0.9928 Balanced Accuracy: 0.9936 \n","Current phase: val\n","val Loss: 0.7113 Acc: 0.8380 Balanced Accuracy: 0.7242 \n","Training complete in 171m 28s\n","Best val Loss: 0.660899\n","Best val Acc: 0.848267\n","Best val Balanced Acc: 0.720630\n","\n"," Final Validation results for BASE: Accuracy: 0.8482672494536372  Balanced Accuracy: 0.720629813158334 \n","\n","{'acc_avg': 0.8482672494536372, 'acc_per_type': array([0.80769231, 0.82340195, 0.85174419, 0.89316988, 0.90291262,\n","       0.86842105]), 'PQD': 0.8945409429280397, 'DPM': 0.4454568368344734, 'EOM': 0.6394507842223532, 'AUC': -1}\n"]}],"source":["!python Base.py --config Fitz17k_configs.yml"]},{"cell_type":"code","source":["!pip install -q backpack-for-pytorch"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lMhuiniqIntU","executionInfo":{"status":"ok","timestamp":1695088026430,"user_tz":-600,"elapsed":5027,"user":{"displayName":"Ali Ghadiri","userId":"10282190092396035743"}},"outputId":"8309c1d3-c5d9-4e96-8d16-bf35b8745f92"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/196.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m163.8/196.4 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.4/196.4 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/42.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"code","execution_count":9,"metadata":{"id":"7ZqlKP_DAq7g","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1695089762487,"user_tz":-600,"elapsed":1062460,"user":{"displayName":"Ali Ghadiri","userId":"10282190092396035743"}},"outputId":"280e6e93-eb04-415c-beca-01c72bb7f847"},"outputs":[{"output_type":"stream","name":"stdout","text":["CUDA is available: True \n","\n","Starting... \n","\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","Loading model from: /content/drive/MyDrive/FairPrune/Outputs/Resnet18_checkpoint_BASE.pth\n","+++++++++++++++++++++++++++++ Pruning Iteration 0 +++++++++++++++++++++++++++++\n","{'train': 8854, 'val': 2209}\n","{'train': 3955, 'val': 994}\n","processing batch 0\n","processing batch 1\n","processing batch 2\n","processing batch 3\n","processing batch 4\n","processing batch 5\n","processing batch 6\n","processing batch 7\n","processing batch 8\n","processing batch 9\n","processing batch 10\n","processing batch 11\n","processing batch 12\n","processing batch 13\n","processing batch 14\n","processing batch 15\n","processing batch 16\n","processing batch 17\n","processing batch 18\n","processing batch 19\n","processing batch 20\n","processing batch 21\n","processing batch 22\n","processing batch 23\n","processing batch 24\n","processing batch 25\n","processing batch 26\n","processing batch 27\n","processing batch 28\n","processing batch 29\n","processing batch 30\n","processing batch 31\n","processing batch 32\n","processing batch 33\n","processing batch 34\n","processing batch 35\n","processing batch 36\n","processing batch 37\n","processing batch 38\n","processing batch 39\n","processing batch 40\n","processing batch 41\n","processing batch 42\n","processing batch 43\n","processing batch 44\n","processing batch 45\n","processing batch 46\n","processing batch 47\n","processing batch 48\n","processing batch 49\n","processing batch 50\n","processing batch 51\n","processing batch 52\n","processing batch 53\n","processing batch 54\n","processing batch 55\n","processing batch 56\n","processing batch 57\n","processing batch 58\n","processing batch 59\n","processing batch 60\n","processing batch 61\n","processing batch 62\n","processing batch 63\n","processing batch 64\n","processing batch 65\n","processing batch 66\n","processing batch 67\n","processing batch 68\n","processing batch 69\n","************************************************************************************************\n","model parameter name: feature_extractor.conv1.weight\n","Pruned pram / total_params: 27 / 9408\n","Statistics of the pruned prams in this parameter:\n","min: -0.8460200428962708 / max: 1.0161234140396118 / mean: 0.00031 / std: 0.12972\n","************************************************************************************************\n","************************************************************************************************\n","model parameter name: feature_extractor.bn1.weight\n","Pruned pram / total_params: 0 / 64\n","Statistics of the pruned prams in this parameter:\n","min: -5.1095959463509644e-08 / max: 0.5266464948654175 / mean: 0.25915 / std: 0.12371\n","************************************************************************************************\n","************************************************************************************************\n","model parameter name: feature_extractor.layer1.0.conv1.weight\n","Pruned pram / total_params: 1993 / 36864\n","Statistics of the pruned prams in this parameter:\n","min: -0.7970645427703857 / max: 0.6763232350349426 / mean: -0.00232 / std: 0.05427\n","************************************************************************************************\n","************************************************************************************************\n","model parameter name: feature_extractor.layer1.0.bn1.weight\n","Pruned pram / total_params: 0 / 64\n","Statistics of the pruned prams in this parameter:\n","min: -0.1969699114561081 / max: 0.0993768572807312 / mean: -0.00848 / std: 0.05623\n","************************************************************************************************\n","************************************************************************************************\n","model parameter name: feature_extractor.layer1.0.conv2.weight\n","Pruned pram / total_params: 1922 / 36864\n","Statistics of the pruned prams in this parameter:\n","min: -0.5349953770637512 / max: 0.6437816619873047 / mean: -0.00039 / std: 0.0472\n","************************************************************************************************\n","************************************************************************************************\n","model parameter name: feature_extractor.layer1.0.bn2.weight\n","Pruned pram / total_params: 13 / 64\n","Statistics of the pruned prams in this parameter:\n","min: -0.3325625956058502 / max: 0.17246663570404053 / mean: 0.00462 / std: 0.07112\n","************************************************************************************************\n","************************************************************************************************\n","model parameter name: feature_extractor.layer1.1.conv1.weight\n","Pruned pram / total_params: 1267 / 36864\n","Statistics of the pruned prams in this parameter:\n","min: -0.5884199738502502 / max: 0.6524803638458252 / mean: -0.00172 / std: 0.05289\n","************************************************************************************************\n","************************************************************************************************\n","model parameter name: feature_extractor.layer1.1.bn1.weight\n","Pruned pram / total_params: 0 / 64\n","Statistics of the pruned prams in this parameter:\n","min: -0.2709389626979828 / max: 0.1060241088271141 / mean: -0.01199 / std: 0.06029\n","************************************************************************************************\n","************************************************************************************************\n","model parameter name: feature_extractor.layer1.1.conv2.weight\n","Pruned pram / total_params: 1070 / 36864\n","Statistics of the pruned prams in this parameter:\n","min: -0.4867764711380005 / max: 0.46156319975852966 / mean: -0.00084 / std: 0.04631\n","************************************************************************************************\n","************************************************************************************************\n","model parameter name: feature_extractor.layer1.1.bn2.weight\n","Pruned pram / total_params: 0 / 64\n","Statistics of the pruned prams in this parameter:\n","min: -0.18833106756210327 / max: 0.09454319626092911 / mean: -0.00709 / std: 0.0526\n","************************************************************************************************\n","************************************************************************************************\n","model parameter name: feature_extractor.layer2.0.conv1.weight\n","Pruned pram / total_params: 1051 / 73728\n","Statistics of the pruned prams in this parameter:\n","min: -0.4161195158958435 / max: 0.7492572069168091 / mean: -0.00109 / std: 0.04352\n","************************************************************************************************\n","************************************************************************************************\n","model parameter name: feature_extractor.layer2.0.bn1.weight\n","Pruned pram / total_params: 0 / 128\n","Statistics of the pruned prams in this parameter:\n","min: -0.09854951500892639 / max: 0.0656573474407196 / mean: -0.00259 / std: 0.02878\n","************************************************************************************************\n","************************************************************************************************\n","model parameter name: feature_extractor.layer2.0.conv2.weight\n","Pruned pram / total_params: 4277 / 147456\n","Statistics of the pruned prams in this parameter:\n","min: -0.3440137505531311 / max: 0.49619659781455994 / mean: -0.00105 / std: 0.0351\n","************************************************************************************************\n","************************************************************************************************\n","model parameter name: feature_extractor.layer2.0.bn2.weight\n","Pruned pram / total_params: 0 / 128\n","Statistics of the pruned prams in this parameter:\n","min: -0.17763634026050568 / max: 0.07767917215824127 / mean: -0.00366 / std: 0.03535\n","************************************************************************************************\n","************************************************************************************************\n","model parameter name: feature_extractor.layer2.0.downsample.0.weight\n","Pruned pram / total_params: 229 / 8192\n","Statistics of the pruned prams in this parameter:\n","min: -0.7816433310508728 / max: 0.6107040643692017 / mean: 0.00181 / std: 0.08065\n","************************************************************************************************\n","************************************************************************************************\n","model parameter name: feature_extractor.layer2.0.downsample.1.weight\n","Pruned pram / total_params: 0 / 128\n","Statistics of the pruned prams in this parameter:\n","min: -0.3063860237598419 / max: 0.16236606240272522 / mean: 0.00054 / std: 0.05235\n","************************************************************************************************\n","************************************************************************************************\n","model parameter name: feature_extractor.layer2.1.conv1.weight\n","Pruned pram / total_params: 4214 / 147456\n","Statistics of the pruned prams in this parameter:\n","min: -0.4567379057407379 / max: 0.7789673209190369 / mean: -0.00115 / std: 0.03464\n","************************************************************************************************\n","************************************************************************************************\n","model parameter name: feature_extractor.layer2.1.bn1.weight\n","Pruned pram / total_params: 0 / 128\n","Statistics of the pruned prams in this parameter:\n","min: -0.05701027065515518 / max: 0.10830465704202652 / mean: 0.00694 / std: 0.03027\n","************************************************************************************************\n","************************************************************************************************\n","model parameter name: feature_extractor.layer2.1.conv2.weight\n","Pruned pram / total_params: 5218 / 147456\n","Statistics of the pruned prams in this parameter:\n","min: -0.49330535531044006 / max: 0.46640732884407043 / mean: -0.00118 / std: 0.03178\n","************************************************************************************************\n","************************************************************************************************\n","model parameter name: feature_extractor.layer2.1.bn2.weight\n","Pruned pram / total_params: 0 / 128\n","Statistics of the pruned prams in this parameter:\n","min: -0.13895274698734283 / max: 0.18868668377399445 / mean: -0.00205 / std: 0.03797\n","************************************************************************************************\n","************************************************************************************************\n","model parameter name: feature_extractor.layer3.0.conv1.weight\n","Pruned pram / total_params: 12303 / 294912\n","Statistics of the pruned prams in this parameter:\n","min: -0.5443638563156128 / max: 0.6429400444030762 / mean: -0.0013 / std: 0.02957\n","************************************************************************************************\n","************************************************************************************************\n","model parameter name: feature_extractor.layer3.0.bn1.weight\n","Pruned pram / total_params: 0 / 256\n","Statistics of the pruned prams in this parameter:\n","min: -0.08277063071727753 / max: 0.11305845528841019 / mean: -0.00405 / std: 0.03206\n","************************************************************************************************\n","************************************************************************************************\n","model parameter name: feature_extractor.layer3.0.conv2.weight\n","Pruned pram / total_params: 35552 / 589824\n","Statistics of the pruned prams in this parameter:\n","min: -0.44288361072540283 / max: 0.5080274343490601 / mean: -0.0007 / std: 0.02526\n","************************************************************************************************\n","************************************************************************************************\n","model parameter name: feature_extractor.layer3.0.bn2.weight\n","Pruned pram / total_params: 14 / 256\n","Statistics of the pruned prams in this parameter:\n","min: -0.06506739556789398 / max: 0.0725899338722229 / mean: -0.00287 / std: 0.02194\n","************************************************************************************************\n","************************************************************************************************\n","model parameter name: feature_extractor.layer3.0.downsample.0.weight\n","Pruned pram / total_params: 1404 / 32768\n","Statistics of the pruned prams in this parameter:\n","min: -0.37539228796958923 / max: 0.6884206533432007 / mean: 0.00024 / std: 0.04302\n","************************************************************************************************\n","************************************************************************************************\n","model parameter name: feature_extractor.layer3.0.downsample.1.weight\n","Pruned pram / total_params: 11 / 256\n","Statistics of the pruned prams in this parameter:\n","min: -0.15587742626667023 / max: 0.08534487336874008 / mean: -0.00181 / std: 0.02823\n","************************************************************************************************\n","************************************************************************************************\n","model parameter name: feature_extractor.layer3.1.conv1.weight\n","Pruned pram / total_params: 38004 / 589824\n","Statistics of the pruned prams in this parameter:\n","min: -0.37539228796958923 / max: 0.29074180126190186 / mean: -0.00161 / std: 0.02179\n","************************************************************************************************\n","************************************************************************************************\n","model parameter name: feature_extractor.layer3.1.bn1.weight\n","Pruned pram / total_params: 7 / 256\n","Statistics of the pruned prams in this parameter:\n","min: -0.07636544108390808 / max: 0.07416322082281113 / mean: 0.00098 / std: 0.01952\n","************************************************************************************************\n","************************************************************************************************\n","model parameter name: feature_extractor.layer3.1.conv2.weight\n","Pruned pram / total_params: 40135 / 589824\n","Statistics of the pruned prams in this parameter:\n","min: -0.6352354884147644 / max: 0.48109814524650574 / mean: -0.00137 / std: 0.02133\n","************************************************************************************************\n","************************************************************************************************\n","model parameter name: feature_extractor.layer3.1.bn2.weight\n","Pruned pram / total_params: 6 / 256\n","Statistics of the pruned prams in this parameter:\n","min: -0.08141151815652847 / max: 0.05582664906978607 / mean: -0.00233 / std: 0.01917\n","************************************************************************************************\n","************************************************************************************************\n","model parameter name: feature_extractor.layer4.0.conv1.weight\n","Pruned pram / total_params: 93784 / 1179648\n","Statistics of the pruned prams in this parameter:\n","min: -0.7271974086761475 / max: 0.6389206647872925 / mean: -0.00147 / std: 0.01965\n","************************************************************************************************\n","************************************************************************************************\n","model parameter name: feature_extractor.layer4.0.bn1.weight\n","Pruned pram / total_params: 26 / 512\n","Statistics of the pruned prams in this parameter:\n","min: -0.17324624955654144 / max: 0.09810949116945267 / mean: -0.00136 / std: 0.02175\n","************************************************************************************************\n","************************************************************************************************\n","model parameter name: feature_extractor.layer4.0.conv2.weight\n","Pruned pram / total_params: 171672 / 2359296\n","Statistics of the pruned prams in this parameter:\n","min: -0.48089632391929626 / max: 0.4173867702484131 / mean: -0.0012 / std: 0.01727\n","************************************************************************************************\n","************************************************************************************************\n","model parameter name: feature_extractor.layer4.0.bn2.weight\n","Pruned pram / total_params: 5 / 512\n","Statistics of the pruned prams in this parameter:\n","min: -0.056610409170389175 / max: 0.06367290765047073 / mean: -0.00268 / std: 0.01745\n","************************************************************************************************\n","************************************************************************************************\n","model parameter name: feature_extractor.layer4.0.downsample.0.weight\n","Pruned pram / total_params: 12928 / 131072\n","Statistics of the pruned prams in this parameter:\n","min: -0.6296059489250183 / max: 0.7433571815490723 / mean: -9e-05 / std: 0.04162\n","************************************************************************************************\n","************************************************************************************************\n","model parameter name: feature_extractor.layer4.0.downsample.1.weight\n","Pruned pram / total_params: 186 / 512\n","Statistics of the pruned prams in this parameter:\n","min: -0.1218961700797081 / max: 0.1527625322341919 / mean: -0.00039 / std: 0.02537\n","************************************************************************************************\n","************************************************************************************************\n","model parameter name: feature_extractor.layer4.1.conv1.weight\n","Pruned pram / total_params: 127363 / 2359296\n","Statistics of the pruned prams in this parameter:\n","min: -0.4076536297798157 / max: 0.4480437934398651 / mean: -0.00234 / std: 0.01787\n","************************************************************************************************\n","************************************************************************************************\n","model parameter name: feature_extractor.layer4.1.bn1.weight\n","Pruned pram / total_params: 1 / 512\n","Statistics of the pruned prams in this parameter:\n","min: -0.04811904951930046 / max: 0.03918023034930229 / mean: -0.00603 / std: 0.01512\n","************************************************************************************************\n","************************************************************************************************\n","model parameter name: feature_extractor.layer4.1.conv2.weight\n","Pruned pram / total_params: 4061 / 2359296\n","Statistics of the pruned prams in this parameter:\n","min: -0.5947139859199524 / max: 0.46228015422821045 / mean: -0.00019 / std: 0.01456\n","************************************************************************************************\n","************************************************************************************************\n","model parameter name: feature_extractor.layer4.1.bn2.weight\n","Pruned pram / total_params: 0 / 512\n","Statistics of the pruned prams in this parameter:\n","min: -0.0354563370347023 / max: 0.09323492646217346 / mean: 0.00197 / std: 0.01534\n","************************************************************************************************\n","************************************************************************************************\n","model parameter name: feature_extractor.fc.weight\n","Pruned pram / total_params: 0 / 1536\n","Statistics of the pruned prams in this parameter:\n","min: -0.03945248946547508 / max: 0.0628267154097557 / mean: -0.00011 / std: 0.01393\n","************************************************************************************************\n"," --------------------------- Pruning Verification ---------------------------\n","\n","Pruned 558743 out of 11173248 parameters\n","\n"," ----------------------------------------------------------------------------\n","{'train': 12809, 'val': 3203}\n","/content/drive/MyDrive/FairPrune/Utils/Metrics.py:47: RuntimeWarning: invalid value encountered in divide\n","  DPM = np.mean(demo_array.min(axis=0) / demo_array.max(axis=0))\n","/content/drive/MyDrive/FairPrune/Utils/Metrics.py:51: RuntimeWarning: invalid value encountered in divide\n","  EOM = np.mean(np.min(eo_array, axis=0) / np.max(eo_array, axis=0))\n","No improvement in the bias metric\n","\n","Traceback (most recent call last):\n","  File \"/content/drive/MyDrive/FairPrune/FairPrune.py\", line 327, in <module>\n","    main(config)\n","  File \"/content/drive/MyDrive/FairPrune/FairPrune.py\", line 309, in main\n","    consecutive_no_improvement += 1\n","UnboundLocalError: local variable 'consecutive_no_improvement' referenced before assignment\n"]}],"source":["!python FairPrune.py --config Fitz17k_configs.yml"]},{"cell_type":"code","source":[],"metadata":{"id":"fDXv-1MmDg0i"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}